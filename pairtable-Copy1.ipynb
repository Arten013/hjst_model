{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hjst_model.config import DatasetKVSConfig, LayerModelConfig\n",
    "from hjst_model import layers\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nmslib\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#カラム内の文字数。デフォルトは50だった\n",
    "pd.set_option(\"display.max_colwidth\", 800)\n",
    "\n",
    "#行数\n",
    "pd.set_option(\"display.max_rows\", 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sentence\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"tokai\"\n",
    "CONF_DIR = './configs{}'.format('')\n",
    "MODEL_DIR = './results/hjst{}/models/'.format('')\n",
    "layer_conf = LayerModelConfig()\n",
    "layer_conf.link(os.path.join(CONF_DIR, './layer.conf'), create_if_missing=True)\n",
    "layer_conf.set_directory(MODEL_DIR, os.path.join(CONF_DIR, 'dataset.conf'))\n",
    "layer_conf.update_file()\n",
    "\n",
    "for l in ['Sentence']:\n",
    "    print('train', l)\n",
    "    #layer_conf.create_layer(dataset_name, layers.TfidfLayer, l, 'tf_tokai_mecab_nolsi', tokenizer=\"mecab\", vocab_size=30000, idf=False, lsi_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = layer_conf.load_model(\"tf_tokai_mecab_nolsi-Sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<1920290x26341 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27653033 stored elements in Compressed Sparse Row format>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/reikiset/01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70dea9812c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestset_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./configs/test/dataset.conf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestset_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_section\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTESTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestset_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hjst_model/hjst_model/config.py\u001b[0m in \u001b[0;36mprepare_dataset\u001b[0;34m(self, registering)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_dataset_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxsize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0madditional_govs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gov_codes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_section_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SECTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hjst_model/hjst_model/hierarchical_dataset.py\u001b[0m in \u001b[0;36mregister_directory\u001b[0;34m(self, basepath, overwrite, maxsize)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mrr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlawdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexist_lawcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TESTSET = \"all\"\n",
    "\n",
    "testset_conf = DatasetKVSConfig()\n",
    "testset_conf.link(\"./configs/test/dataset.conf\")\n",
    "testset_conf.change_section(TESTSET)\n",
    "testset = testset_conf.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare layer config instance\n",
    "layerconf = LayerModelConfig()\n",
    "layerconf.link(\"./configs/layer.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentence layer\n",
    "layerconf.change_section(\"wva_tokai_spm_16000-Sentence\")\n",
    "sentence_layer = layerconf.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load law layer\n",
    "layerconf.change_section(\"wva_tokai_spm_16000-Law\")\n",
    "law_layer = layerconf.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.set_iterator_mode(level=\"Law\", tag=True, sentence=False)\n",
    "law_tags = [tag for tag in testset]\n",
    "law_vectors = np.matrix([law_layer[tag] for tag in law_tags])\n",
    "print(law_vectors.shape)\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity\n",
    "law_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "law_index.addDataPointBatch(law_vectors)\n",
    "law_index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "law_neighbours = law_index.knnQueryBatch(law_vectors, k=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.set_iterator_mode(level=\"Sentence\", tag=True, sentence=False)\n",
    "sentence_tags = [tag for tag in testset]\n",
    "sentence_vectors = np.matrix([sentence_layer[tag] for tag in sentence_tags])\n",
    "print(sentence_vectors.shape)\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity\n",
    "sentence_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "sentence_index.addDataPointBatch(sentence_vectors)\n",
    "sentence_index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "sentence_neighbours = sentence_index.knnQueryBatch(sentence_vectors, k=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ([ids, distances] for ids, distances in law_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltag_gen = (ltag for ltag in law_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# setting\n",
    "k = 3\n",
    "\n",
    "# get query law tag\n",
    "query = next(ltag_gen)\n",
    "\n",
    "# get similar law tags and vectors(= simple method output)\n",
    "target_law_indices, _ = law_index.knnQuery(law_layer[query], k=k+1)\n",
    "target_law_tags = [law_tags[i] for i in target_law_indices if law_tags[i] != query][:k]\n",
    "\n",
    "# construct target sentence space\n",
    "target_spaces = dict()\n",
    "target_sentence_tags = dict()\n",
    "for ltag in target_law_tags:\n",
    "    testset.set_iterator_mode(level=\"Sentence\", tag=True, sentence=False)\n",
    "    target_sentence_tags[ltag] = [stag for atag in testset['edges']['Law'][ltag] for stag in testset['edges']['Article'][atag]]\n",
    "    target_sentence_vectors = np.matrix([sentence_layer[tag] for tag in target_sentence_tags[ltag]])\n",
    "\n",
    "    # initialize a new index, using a HNSW index on Cosine Similarity\n",
    "    target_spaces[ltag] = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "    target_spaces[ltag].addDataPointBatch(target_sentence_vectors)\n",
    "    target_spaces[ltag].createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "columns = [str(testset.kvsdicts[\"root\"][os.path.split(tag)[0]])+\"({})\".format(os.path.split(tag)[0]) for tag in [query]+target_law_tags]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "sid = 0\n",
    "for a in testset.kvsdicts[\"edges\"][\"Law\"][query]:\n",
    "    for j, s in enumerate(testset.kvsdicts[\"edges\"][\"Article\"][a]):\n",
    "        sid += 1\n",
    "        df.loc[sid, columns[0]] = testset.kvsdicts[\"texts\"][\"Sentence\"][s]\n",
    "        for l, ltag in enumerate(target_law_tags):\n",
    "            index = target_spaces[ltag]\n",
    "            resi, resd  = index.knnQuery(sentence_layer[s], 1)\n",
    "            df.loc[sid, columns[l+1]] = testset.kvsdicts[\"texts\"][\"Sentence\"][target_sentence_tags[ltag][resi[0]]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = 0\n",
    "for a in testset.kvsdicts[\"edges\"][\"Law\"][query]:\n",
    "    for t, s in enumerate(testset.kvsdicts[\"edges\"][\"Article\"][a]):\n",
    "        sid += 1\n",
    "        print(sid, s)#, testset.kvsdicts[\"texts\"][\"Sentence\"][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for the nearest neighbours of the first datapoint\n",
    "ids, distances = next(gen)\n",
    "import os\n",
    "for i in range(10):\n",
    "    tag = law_tags[ids[i]]\n",
    "    print(tag)\n",
    "    print(i, round(distances[i], 3), testset.kvsdicts[\"root\"][os.path.split(tag)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit tree.sparse_distance_matrix(tree, 0.6).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
